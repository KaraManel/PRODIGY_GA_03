{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8930439,"sourceType":"datasetVersion","datasetId":5372266}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"text_a = open(\"/kaggle/input/text-generation-dataset/1342-0.txt\").read()\ntext_b = open(\"/kaggle/input/text-generation-dataset/84-0.txt\").read()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:12:09.862299Z","iopub.execute_input":"2024-07-11T12:12:09.863018Z","iopub.status.idle":"2024-07-11T12:12:09.878673Z","shell.execute_reply.started":"2024-07-11T12:12:09.862988Z","shell.execute_reply":"2024-07-11T12:12:09.877970Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"a_words = text_a.split()\nb_words = text_b.split()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:12:09.880200Z","iopub.execute_input":"2024-07-11T12:12:09.880464Z","iopub.status.idle":"2024-07-11T12:12:09.908611Z","shell.execute_reply.started":"2024-07-11T12:12:09.880442Z","shell.execute_reply":"2024-07-11T12:12:09.907567Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import sys\n!{sys.executable} -m pip install markovify","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:12:09.909752Z","iopub.execute_input":"2024-07-11T12:12:09.910023Z","iopub.status.idle":"2024-07-11T12:12:22.223570Z","shell.execute_reply.started":"2024-07-11T12:12:09.909996Z","shell.execute_reply":"2024-07-11T12:12:22.222449Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Requirement already satisfied: markovify in /opt/conda/lib/python3.10/site-packages (0.9.4)\nRequirement already satisfied: unidecode in /opt/conda/lib/python3.10/site-packages (from markovify) (1.3.8)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"And then run this cell to make the library available in your notebook:","metadata":{}},{"cell_type":"code","source":"import markovify","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:12:22.224909Z","iopub.execute_input":"2024-07-11T12:12:22.225176Z","iopub.status.idle":"2024-07-11T12:12:22.229779Z","shell.execute_reply.started":"2024-07-11T12:12:22.225151Z","shell.execute_reply":"2024-07-11T12:12:22.228791Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"The code in the following cell creates a new text generator, using the text in the variable specified to build the Markov model, which is then assigned to the variable `generator_a`.","metadata":{}},{"cell_type":"code","source":"generator_a = markovify.Text(text_a)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:12:22.232591Z","iopub.execute_input":"2024-07-11T12:12:22.233133Z","iopub.status.idle":"2024-07-11T12:12:22.882281Z","shell.execute_reply.started":"2024-07-11T12:12:22.233076Z","shell.execute_reply":"2024-07-11T12:12:22.881254Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"You can then call the `.make_sentence()` method to generate a sentence from the model:","metadata":{}},{"cell_type":"code","source":"print(generator_a.make_sentence())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:12:22.883489Z","iopub.execute_input":"2024-07-11T12:12:22.883795Z","iopub.status.idle":"2024-07-11T12:12:22.896611Z","shell.execute_reply.started":"2024-07-11T12:12:22.883771Z","shell.execute_reply":"2024-07-11T12:12:22.895610Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Such was Miss Lucas and Mrs. Gardiner had formed, of their meeting in Derbyshire, so often, and in a family on which her marriage would so shortly give the matter had ever raised before; she remembered the style of living in the recital which I want to think it no otherwise than lovely and amiable.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The `.make_short_sentence()` method allows you to specify a maximum length for the generated sentence:","metadata":{}},{"cell_type":"code","source":"print(generator_a.make_short_sentence(50))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:12:22.897667Z","iopub.execute_input":"2024-07-11T12:12:22.897972Z","iopub.status.idle":"2024-07-11T12:12:22.920432Z","shell.execute_reply.started":"2024-07-11T12:12:22.897943Z","shell.execute_reply":"2024-07-11T12:12:22.919469Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"We must not suspect me.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"By default, Markovify tries to generate a sentence that is significantly different from any existing sentence in the input text. As a consequence, sometimes the `.make_sentence()` or `.make_short_sentence()` methods will return `None`, which means that in ten tries it wasn't able to generate such a sentence. You can work around this by increasing the number of times it tries to generate a sufficiently unique sentence using the `tries` parameter:","metadata":{}},{"cell_type":"code","source":"print(generator_a.make_short_sentence(40, tries=100))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:12:22.921669Z","iopub.execute_input":"2024-07-11T12:12:22.922120Z","iopub.status.idle":"2024-07-11T12:12:22.930470Z","shell.execute_reply.started":"2024-07-11T12:12:22.922094Z","shell.execute_reply":"2024-07-11T12:12:22.929458Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Accordingly, when she had chosen.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Or by disabling the check altogether with `test_output=False` (note that this means the generator will occasionally return stretches of text that are present in the source text):","metadata":{}},{"cell_type":"code","source":"print(generator_a.make_short_sentence(40, test_output=False))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:12:22.931666Z","iopub.execute_input":"2024-07-11T12:12:22.932032Z","iopub.status.idle":"2024-07-11T12:12:22.940538Z","shell.execute_reply.started":"2024-07-11T12:12:22.931998Z","shell.execute_reply":"2024-07-11T12:12:22.939512Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"None\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Changing the order\n\nWhen you create the model, you can specify the order of the model using the `state_size` parameter. It defaults to 2. Let's make two model with different orders and compare:","metadata":{}},{"cell_type":"code","source":"gen_a_1 = markovify.Text(text_a, state_size=1)\ngen_a_4 = markovify.Text(text_a, state_size=4)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:12:22.941795Z","iopub.execute_input":"2024-07-11T12:12:22.942118Z","iopub.status.idle":"2024-07-11T12:12:24.243799Z","shell.execute_reply.started":"2024-07-11T12:12:22.942088Z","shell.execute_reply":"2024-07-11T12:12:24.242773Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print(\"order 1\")\nprint(gen_a_1.make_sentence(test_output=False))\nprint()\nprint(\"order 4\")\nprint(gen_a_4.make_sentence(test_output=False))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:12:24.245127Z","iopub.execute_input":"2024-07-11T12:12:24.245437Z","iopub.status.idle":"2024-07-11T12:12:24.253613Z","shell.execute_reply.started":"2024-07-11T12:12:24.245410Z","shell.execute_reply":"2024-07-11T12:12:24.252664Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"order 1\nI endeavoured to all his return into something to be only creature in talking together, a less pliancy of her spirits; and on Wickham's circumstances are poor.\n\norder 4\nIt is highly improper.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"In general, the higher the order, the more the sentences will seem \"coherent\" (i.e., more closely resembling the source text). Lower order models will produce more variation. Deciding on the order is usually a matter of taste and trial-and-error.","metadata":{}},{"cell_type":"markdown","source":"### Changing the level\n\nMarkovify, by default, works with *words* as the individual unit. It doesn't come out-of-the-box with support for character-level models. The following code defines a new kind of Markovify generator that implements character-level models. Execute it before continuing:","metadata":{}},{"cell_type":"code","source":"class SentencesByChar(markovify.Text):\n    def word_split(self, sentence):\n        return list(sentence)\n    def word_join(self, words):\n        return \"\".join(words)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:17:32.475650Z","iopub.execute_input":"2024-07-11T12:17:32.476354Z","iopub.status.idle":"2024-07-11T12:17:32.481282Z","shell.execute_reply.started":"2024-07-11T12:17:32.476323Z","shell.execute_reply":"2024-07-11T12:17:32.480400Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"Any of the parameters you passed to `markovify.Text` you can also pass to `SentencesByChar`. The `state_size` parameter still controls the order of the model, but now the n-grams are characters, not words.\n\nThe following cell implements a character-level Markov text generator for the word \"condescendences\":","metadata":{}},{"cell_type":"code","source":"con_model = SentencesByChar(\"condescendences\", state_size=2)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:18:29.515564Z","iopub.execute_input":"2024-07-11T12:18:29.515917Z","iopub.status.idle":"2024-07-11T12:18:29.520398Z","shell.execute_reply.started":"2024-07-11T12:18:29.515891Z","shell.execute_reply":"2024-07-11T12:18:29.519418Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"Execute the cell below to see the output—it'll be a lot like what we implemented by hand earlier!","metadata":{}},{"cell_type":"code","source":"con_model.make_sentence()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:18:32.656896Z","iopub.execute_input":"2024-07-11T12:18:32.657511Z","iopub.status.idle":"2024-07-11T12:18:32.663507Z","shell.execute_reply.started":"2024-07-11T12:18:32.657475Z","shell.execute_reply":"2024-07-11T12:18:32.662604Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'condendescences'"},"metadata":{}}]},{"cell_type":"markdown","source":"Of course, you can use a character-level model on any text of your choice. So, for example, the following cell creates a character-level order-7 Markov chain text generator from text A:","metadata":{}},{"cell_type":"code","source":"gen_a_char = SentencesByChar(text_a, state_size=7)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:18:34.563433Z","iopub.execute_input":"2024-07-11T12:18:34.564371Z","iopub.status.idle":"2024-07-11T12:18:35.690237Z","shell.execute_reply.started":"2024-07-11T12:18:34.564328Z","shell.execute_reply":"2024-07-11T12:18:35.689430Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"And the cell below prints out a random sentence from this generator. (The `.replace()` is to get rid of any newline characters in the output.)","metadata":{}},{"cell_type":"code","source":"print(gen_a_char.make_sentence(test_output=False).replace(\"\\n\", \" \"))","metadata":{"execution":{"iopub.status.busy":"2024-07-11T12:18:46.715386Z","iopub.execute_input":"2024-07-11T12:18:46.715719Z","iopub.status.idle":"2024-07-11T12:18:46.721199Z","shell.execute_reply.started":"2024-07-11T12:18:46.715694Z","shell.execute_reply":"2024-07-11T12:18:46.720229Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Widely different people's engagement, they were not a doubt his antagonist at backgammon.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Combining models\n\nMarkovify has a handy feature that allows you to *combine* models, creating a new model that draws on probabilities from both of the source models. You can use this to create hybrid output that mixes the style and content of two (or more!) different source texts. To do this, you need to create the models independently, and then call `.combine()` to combine them.","metadata":{}},{"cell_type":"code","source":"generator_a = markovify.Text(text_a)\ngenerator_b = markovify.Text(text_b)\ncombo = markovify.combine([generator_a, generator_b], [0.5, 0.5])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:18:50.715428Z","iopub.execute_input":"2024-07-11T12:18:50.715820Z","iopub.status.idle":"2024-07-11T12:18:51.915538Z","shell.execute_reply.started":"2024-07-11T12:18:50.715790Z","shell.execute_reply":"2024-07-11T12:18:51.914204Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"The bit of code `[0.5, 0.5]` controls the \"weights\" of the models, i.e., how much to emphasize the probabilities of any model. You can change this to suit your tastes. (E.g., if you want mostly text A with but a *soupçon* of text B, you would write `[0.9, 0.1]`. Try it!) \n\nThen you can create sentences using the combined model:","metadata":{}},{"cell_type":"code","source":"print(combo.make_sentence())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:18:55.063417Z","iopub.execute_input":"2024-07-11T12:18:55.064234Z","iopub.status.idle":"2024-07-11T12:18:55.070949Z","shell.execute_reply.started":"2024-07-11T12:18:55.064199Z","shell.execute_reply":"2024-07-11T12:18:55.069799Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"And then, you know, and I only mean to lecture you a second time, therefore, was most anxious to get home.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Bringing it all together\n\nI've pre-written some code below to make it easy for you to experiment and produce output from Markovify. Just make adjustments to the values assigned to the variables in the cell below:","metadata":{}},{"cell_type":"code","source":"# change to \"word\" for a word-level model\nlevel = \"char\"\n# controls the length of the n-gram\norder = 7\n# controls the number of lines to output\noutput_n = 14\n# weights between the models; text A first, text B second.\n# if you want to completely exclude one model, set its corresponding value to 0\nweights = [0.5, 0.5]\n# limit sentence output to this number of characters\nlength_limit = 280","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:18:56.452510Z","iopub.execute_input":"2024-07-11T12:18:56.452867Z","iopub.status.idle":"2024-07-11T12:18:56.457807Z","shell.execute_reply.started":"2024-07-11T12:18:56.452839Z","shell.execute_reply":"2024-07-11T12:18:56.456789Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"(The lines beginning with `#` are \"comments\"—they don't do anything, they're just there to explain what's happening in the code.)\n\nAfter making your changes above, run the cell below to generate text according to your parameters. Repeat as necessary until you get something you really like!","metadata":{}},{"cell_type":"code","source":"model_cls = markovify.Text if level == \"word\" else SentencesByChar\ngen_a = model_cls(text_a, state_size=order)\ngen_b = model_cls(text_b, state_size=order)\ngen_combo = markovify.combine([gen_a, gen_b], weights)\nfor i in range(output_n):\n    out = gen_combo.make_short_sentence(length_limit, test_output=False)\n    out = out.replace(\"\\n\", \" \")\n    print(out)\n    print()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-07-11T12:18:58.015393Z","iopub.execute_input":"2024-07-11T12:18:58.015707Z","iopub.status.idle":"2024-07-11T12:19:00.406202Z","shell.execute_reply.started":"2024-07-11T12:18:58.015683Z","shell.execute_reply":"2024-07-11T12:19:00.405270Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Who would have been passive, if you did love my chains, whose disposed about it is not enough to endured rendered as Lydia's charge, how much to Elizabeth felt the sole expected.\n\nI repassed, in the sun or gentle demeanour and admiration of you is, to my solitary cottage, in which had creator; he was less strangeness of her chair, my eyes.\n\nNo one way over the generous cave and aid, he so justly scorned.\n\nWhen, after success, for the North, received and misery.\n\nIt advanced by Henry, languish was to endured.\n\nWhat a disgraceful company of your account of the dæmons of revenge, henceforth dearer friends to his tale of scaling this exposing and fainted.\n\nAll were silent acquaintance which was not that blame which led me that as I plunge me lower in the kind of promise you have promised my path lay through her rays, while his wife; but his marriage.\n\nEager to satisfaction and vengeance she had force of reflected, yet I own to pursue any measure of Wickham really happy together he was joined by the arrival, or even fresh source of instruction and desirous of having a confirmed them, loud and repeated herself.\n\nHe looked at her for another sleep, and lastly of my heart sickening fair.\n\ncried Mrs. Hurst and connected with one of that remained to the groans from people start at our Web site including horror and written in the lawn afterwards this place in Ireland, allow me to love, and the way.\n\nAnd as I advancing was the sensations to a race of some very bare of beauty, succeeded and meanest desired to diverted by the favourably alone.\n\nAll that she could disclosure.\n\nI am prodigiously assurances of attachment.\n\nI am sorry for a moment the carriage was sufficient to get the past appear to me, I wept like it, however, his credit to--but he raised the innocent and craving; still more gloom and misery.\n\n","output_type":"stream"}]}]}